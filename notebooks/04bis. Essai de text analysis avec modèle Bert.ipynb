{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "446962b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "df = pd.read_csv('data_tokenized_2609_doctr_trad V2.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "203425b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>type</th>\n",
       "      <th>size</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>mots_doctr</th>\n",
       "      <th>nb_mots</th>\n",
       "      <th>mots_concat</th>\n",
       "      <th>Langue</th>\n",
       "      <th>mots_doctr_trad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_0000000.jpg</td>\n",
       "      <td>facture</td>\n",
       "      <td>59453</td>\n",
       "      <td>750</td>\n",
       "      <td>1061</td>\n",
       "      <td>['factur', 'logo', 'joanner', 'binet', 'couber...</td>\n",
       "      <td>55</td>\n",
       "      <td>factur logo joanner binet coubertin pari factu...</td>\n",
       "      <td>fr</td>\n",
       "      <td>['bill', 'logo', 'joanner', 'binet', 'couberti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_0000001.jpg</td>\n",
       "      <td>facture</td>\n",
       "      <td>55157</td>\n",
       "      <td>750</td>\n",
       "      <td>1061</td>\n",
       "      <td>['joanner', 'binet', 'coubertin', 'pari', 'fac...</td>\n",
       "      <td>53</td>\n",
       "      <td>joanner binet coubertin pari factur facturé ce...</td>\n",
       "      <td>fr</td>\n",
       "      <td>['joanner', 'binet', 'coubertine', 'bet', 'bil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_0000002.jpg</td>\n",
       "      <td>facture</td>\n",
       "      <td>32097</td>\n",
       "      <td>726</td>\n",
       "      <td>1024</td>\n",
       "      <td>['factur', 'entreprise', 'nom', 'société', 'ad...</td>\n",
       "      <td>28</td>\n",
       "      <td>factur entreprise nom société adresse postal a...</td>\n",
       "      <td>fr</td>\n",
       "      <td>['bill', 'enterprise', 'name', 'company', 'Add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_0000003.jpg</td>\n",
       "      <td>facture</td>\n",
       "      <td>63937</td>\n",
       "      <td>750</td>\n",
       "      <td>1061</td>\n",
       "      <td>['joanner', 'binet', 'coubertin', 'pari', 'fac...</td>\n",
       "      <td>53</td>\n",
       "      <td>joanner binet coubertin pari factur cendrillon...</td>\n",
       "      <td>fr</td>\n",
       "      <td>['joanner', 'binet', 'coubertine', 'bet', 'bil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_0000004.jpg</td>\n",
       "      <td>facture</td>\n",
       "      <td>79474</td>\n",
       "      <td>773</td>\n",
       "      <td>771</td>\n",
       "      <td>['payer', 'ligne', 'factur', 'sfideli', 'date'...</td>\n",
       "      <td>63</td>\n",
       "      <td>payer ligne factur sfideli date création date ...</td>\n",
       "      <td>fr</td>\n",
       "      <td>['pay', 'line', 'bill', 'sfideli', 'date', 'es...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename     type   size  width  height  \\\n",
       "0  img_0000000.jpg  facture  59453    750    1061   \n",
       "1  img_0000001.jpg  facture  55157    750    1061   \n",
       "2  img_0000002.jpg  facture  32097    726    1024   \n",
       "3  img_0000003.jpg  facture  63937    750    1061   \n",
       "4  img_0000004.jpg  facture  79474    773     771   \n",
       "\n",
       "                                          mots_doctr  nb_mots  \\\n",
       "0  ['factur', 'logo', 'joanner', 'binet', 'couber...       55   \n",
       "1  ['joanner', 'binet', 'coubertin', 'pari', 'fac...       53   \n",
       "2  ['factur', 'entreprise', 'nom', 'société', 'ad...       28   \n",
       "3  ['joanner', 'binet', 'coubertin', 'pari', 'fac...       53   \n",
       "4  ['payer', 'ligne', 'factur', 'sfideli', 'date'...       63   \n",
       "\n",
       "                                         mots_concat Langue  \\\n",
       "0  factur logo joanner binet coubertin pari factu...     fr   \n",
       "1  joanner binet coubertin pari factur facturé ce...     fr   \n",
       "2  factur entreprise nom société adresse postal a...     fr   \n",
       "3  joanner binet coubertin pari factur cendrillon...     fr   \n",
       "4  payer ligne factur sfideli date création date ...     fr   \n",
       "\n",
       "                                     mots_doctr_trad  \n",
       "0  ['bill', 'logo', 'joanner', 'binet', 'couberti...  \n",
       "1  ['joanner', 'binet', 'coubertine', 'bet', 'bil...  \n",
       "2  ['bill', 'enterprise', 'name', 'company', 'Add...  \n",
       "3  ['joanner', 'binet', 'coubertine', 'bet', 'bil...  \n",
       "4  ['pay', 'line', 'bill', 'sfideli', 'date', 'es...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb661dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1134, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbab0b5",
   "metadata": {},
   "source": [
    "On s'assure tout d'abord que le dataframe est bien lisible et utilisable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "385e0b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexj\\AppData\\Local\\Temp\\ipykernel_3212\\1114243190.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['mots_doctr_trad'][i] = r2.sub(' ', str(df['mots_doctr_trad'][i]))\n",
      "C:\\Users\\alexj\\AppData\\Local\\Temp\\ipykernel_3212\\1114243190.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['mots_doctr_trad'][i] = df['mots_doctr_trad'][i].replace(\"   \", \" \").replace(\"  \", \" \").lower()\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "r2 = re.compile(r\"[^a-zA-Zéèàùôâêëäïöü]\")\n",
    "for i in range(df.shape[0]):\n",
    "    df['mots_doctr_trad'][i] = r2.sub(' ', str(df['mots_doctr_trad'][i]))\n",
    "    df['mots_doctr_trad'][i] = df['mots_doctr_trad'][i].replace(\"   \", \" \").replace(\"  \", \" \").lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c66de13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'factur logo joanner binet coubertin pari factur cendrillon ayot rue nation pari envoye cendrillon ayot rue ferréol lle france factur date commande ance prix unit total tva total montant designation grand brun escargot manger petit marinière uniforme bleu facile jouer accordéon buncht condition modalit paiemer paiemer jour caisse epargne iban swift bic abcdfrp xxx merci '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df['mots_concat'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01e90ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' bill logo joanner binet coubertine bet bill butterfly ayot street nation bet send butterfly ayot street ferreol it s all right  france bill date command benance prices unit total tva total amount designation large brown snail eat small marine uniform blue easy play accordion buncht condition modality paying paying day body saving iban swift bic abcdfrp xxx thank you '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mots_doctr_trad'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fefaac",
   "metadata": {},
   "source": [
    "On supprime les colonnes qui ne seront pas utiles dans cette analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49a101d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['mots_doctr', 'nb_mots', 'Langue', 'mots_concat'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55bb9149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>type</th>\n",
       "      <th>size</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>mots_doctr_trad</th>\n",
       "      <th>type_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_0000000.jpg</td>\n",
       "      <td>facture</td>\n",
       "      <td>59453</td>\n",
       "      <td>750</td>\n",
       "      <td>1061</td>\n",
       "      <td>bill logo joanner binet coubertine bet bill b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_0000001.jpg</td>\n",
       "      <td>facture</td>\n",
       "      <td>55157</td>\n",
       "      <td>750</td>\n",
       "      <td>1061</td>\n",
       "      <td>joanner binet coubertine bet bill billed butt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_0000002.jpg</td>\n",
       "      <td>facture</td>\n",
       "      <td>32097</td>\n",
       "      <td>726</td>\n",
       "      <td>1024</td>\n",
       "      <td>bill enterprise name company address postal a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_0000003.jpg</td>\n",
       "      <td>facture</td>\n",
       "      <td>63937</td>\n",
       "      <td>750</td>\n",
       "      <td>1061</td>\n",
       "      <td>joanner binet coubertine bet bill butterfly a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_0000004.jpg</td>\n",
       "      <td>facture</td>\n",
       "      <td>79474</td>\n",
       "      <td>773</td>\n",
       "      <td>771</td>\n",
       "      <td>pay line bill sfideli date establishment date...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename     type   size  width  height  \\\n",
       "0  img_0000000.jpg  facture  59453    750    1061   \n",
       "1  img_0000001.jpg  facture  55157    750    1061   \n",
       "2  img_0000002.jpg  facture  32097    726    1024   \n",
       "3  img_0000003.jpg  facture  63937    750    1061   \n",
       "4  img_0000004.jpg  facture  79474    773     771   \n",
       "\n",
       "                                     mots_doctr_trad  type_num  \n",
       "0   bill logo joanner binet coubertine bet bill b...         0  \n",
       "1   joanner binet coubertine bet bill billed butt...         0  \n",
       "2   bill enterprise name company address postal a...         0  \n",
       "3   joanner binet coubertine bet bill butterfly a...         0  \n",
       "4   pay line bill sfideli date establishment date...         0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84127ffe",
   "metadata": {},
   "source": [
    "On recréé une colonne mots_concat à partir de la traduction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4e7f12",
   "metadata": {},
   "source": [
    "Enfin, en se basant sur l'interprétation des résultats de l'itération précédente, on va rassembler les catégories \"rrc.cvc\", \"scientific_publication\" et \"scientific_report\", très similaires et difficiles à dissocier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5da7eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'] = df['type'].replace(['rrc.cvc', 'scientific_publication', 'scientific_report'], ['scientific_doc', 'scientific_doc', 'scientific_doc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4b9f3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scientific_doc     351\n",
       "paye               145\n",
       "id_pieces           82\n",
       "carte postale       70\n",
       "facture             66\n",
       "passeport           43\n",
       "handwritten         35\n",
       "news_article        32\n",
       "memo                31\n",
       "questionnaire       31\n",
       "resume              30\n",
       "letter              29\n",
       "budget              25\n",
       "presentation        25\n",
       "specification       24\n",
       "invoice             24\n",
       "advertisement       23\n",
       "justif_domicile     23\n",
       "email               23\n",
       "form                22\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e3f8555",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type_num'] = df.type.replace(df.type.unique().tolist(), [x for x in range(len(df['type'].unique()))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505d08be",
   "metadata": {},
   "source": [
    "On sépare le dataset en un ensemble d'entrainement et un ensemble de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fa050a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.mots_doctr_trad\n",
    "y = df.type_num\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25a7f21",
   "metadata": {},
   "source": [
    "Puis on vient charger un modèle BERT pré-entrainé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c1b5d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "\n",
    "model = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8066f9c2",
   "metadata": {},
   "source": [
    "Et on encode les informations afin qu'elles soient utilisables par le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af74bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 512\n",
    "\n",
    "X_train_encoded = tokenizer(\n",
    "    list(X_train), truncation=True, padding=True, max_length=max_length)\n",
    "X_test_encoded = tokenizer(list(X_test), truncation=True,\n",
    "                           padding=True, max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ddd335b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  5,  6,  6, 15,  6,  6, 11, 11,  3,  6, 12, 15,  8,  6, 14,  4,\n",
       "       18,  6,  6, 13, 14,  6,  6, 16,  4,  5,  6,  0,  0, 10, 11,  9,  4,\n",
       "        4,  7, 10, 14,  4, 19,  5,  6,  6, 12,  4,  4,  0,  6,  0,  1,  0,\n",
       "        5,  3,  1,  6,  4,  5,  1,  6, 19,  4, 15,  6,  6,  4,  5, 10,  6,\n",
       "        8, 17,  6,  9,  6,  0, 15,  1, 16, 19, 17,  4, 13,  6, 17,  3, 10,\n",
       "        4,  1,  6, 16,  6, 12, 18, 18,  4,  6,  6,  6, 17,  1,  6,  5, 17,\n",
       "       19,  6,  6,  0,  2,  4,  4,  4,  6, 18,  6,  6, 11, 13,  6, 18,  6,\n",
       "        6,  0,  5,  6, 14,  5,  4,  6,  4, 10,  4,  4, 10,  6,  4, 12,  6,\n",
       "       14,  4,  6, 11,  1,  1,  6,  0,  7,  6,  4,  3,  6,  6, 17,  5,  1,\n",
       "        1,  6,  1, 17,  6,  6, 19,  6, 19,  6,  4,  5,  0,  4, 12,  6,  1,\n",
       "        1,  6, 14,  4,  6,  6,  0,  4, 11,  4,  6,  4,  6,  1, 10,  6,  6,\n",
       "        1,  9,  6,  4, 19,  4,  6,  0,  6, 14,  3,  6,  5,  1,  5,  6,  6,\n",
       "       11, 17,  6,  4,  6,  3, 17, 13,  1,  6,  6,  4, 19,  9, 18, 15,  3,\n",
       "        9,  6,  1,  6,  6, 16, 14,  0, 13,  2,  7,  4,  6,  6,  4,  4,  6,\n",
       "        6,  6,  6, 15,  9,  6,  6,  6,  6,  6,  6,  6,  6,  6, 17,  6,  6,\n",
       "       13,  7,  2,  4,  6, 19,  3, 16,  1,  2,  4,  4,  6,  6,  6,  0,  6,\n",
       "        1, 15,  6,  6,  4,  5,  6,  9,  6,  6, 11,  6, 12,  0,  5, 17,  6,\n",
       "       18, 14,  3,  6,  1, 11,  1, 17,  3,  6, 10,  4,  1,  1,  4,  6,  4,\n",
       "       17,  6,  6,  6,  6,  4,  6,  2,  0,  6,  3, 14,  2, 17,  3,  6, 19,\n",
       "        6,  6,  1, 18,  4,  4,  6,  1,  6, 15,  3,  0,  1, 11, 10, 17, 18,\n",
       "        6,  6,  0,  6,  6,  6,  8,  5, 12,  6,  5,  6,  4,  6, 15,  6,  5,\n",
       "        3,  0,  6,  6,  0,  4, 12,  4, 10,  5, 17,  6, 16,  6, 12,  9,  6,\n",
       "        5, 10, 15,  5,  5,  1, 11,  6,  6,  1,  5,  6,  6,  1, 15,  6,  6,\n",
       "        6, 12,  0,  5, 13,  7,  0,  2,  5,  6,  6, 10,  5,  6, 13, 17, 10,\n",
       "       15,  4,  4,  0, 18,  4, 18,  9,  4,  3,  1,  6,  0,  4,  6,  9,  6,\n",
       "       19,  4,  6,  6,  4,  3,  8,  1,  6,  1,  6,  4, 19,  6,  6,  2,  1,\n",
       "        9,  6,  6,  3,  4,  4,  6, 11,  6,  1, 16,  6,  6,  6,  6, 12, 19,\n",
       "        1,  1,  6,  6,  0,  6,  6,  6,  6, 18,  1,  6,  5,  4,  6,  0,  4,\n",
       "        3,  1,  0, 12, 13,  6,  4, 15,  6, 12, 11, 13,  4,  4, 10,  4,  2,\n",
       "        1, 14,  6,  6,  6,  0,  6,  4, 19,  1,  6,  6,  5, 16,  4,  0,  6,\n",
       "       18, 17, 16,  5,  6, 10, 19,  0,  3,  4, 17, 15, 15,  6,  2,  6,  6,\n",
       "        4,  6,  6,  9,  6, 15, 13,  0,  1,  4,  4, 12, 17,  3,  1, 12,  6,\n",
       "        6,  3,  4,  8,  9, 11, 12, 10, 11,  6,  5,  0,  6,  2, 10,  3,  0,\n",
       "        6,  0,  3,  6,  6, 14, 11,  6,  4, 15,  6,  7,  4,  0, 14, 10,  6,\n",
       "        6,  5,  4,  0,  6,  9, 15,  5,  6,  9,  6,  0, 17,  8,  3, 11,  6,\n",
       "        6, 18, 12,  8, 16,  6,  2,  6, 10,  2,  7,  6, 10,  2, 14,  8,  6,\n",
       "        1,  4, 14,  1,  5,  5, 13,  6, 14,  6,  1,  0,  2,  5,  7,  3, 17,\n",
       "        6, 11, 19,  0, 18,  0,  6,  6,  4,  4, 15,  6,  6, 12,  8, 13,  4,\n",
       "        6,  4,  5,  2, 17, 13,  6,  7,  8,  6,  6,  6,  7,  6, 12,  1,  1,\n",
       "       17,  4, 12,  7,  6,  6,  4,  6,  4,  3,  1,  8,  6,  1, 17, 13,  3,\n",
       "        6, 14,  6,  4,  4, 13,  5,  1,  3,  3,  6, 13,  4,  5, 16, 17, 11,\n",
       "        7,  0,  1,  6,  5,  9, 16,  8,  9,  6,  4,  6,  0, 16, 15,  1,  6,\n",
       "       17, 16,  5, 17, 17,  6,  4, 12,  6,  6, 13,  1,  6,  4,  6,  6,  6,\n",
       "        5,  9,  6,  8,  4,  6,  6,  6,  4,  6,  5, 19,  6,  4,  4,  6, 14,\n",
       "        6,  6, 16,  4,  5,  5,  4,  9, 15,  6,  4,  6,  6, 15,  6,  6,  4,\n",
       "        6,  6,  0,  6,  6,  9,  6,  6,  6,  6,  9,  1,  4,  6,  9,  2,  6,\n",
       "        0,  6,  2,  6,  7, 11, 19,  6, 12,  7,  1,  8,  6,  4, 10,  7, 16,\n",
       "        3,  5,  7,  8,  5, 12,  9, 13,  6,  6, 19,  7,  6,  1, 16,  5,  6,\n",
       "       12,  6,  3,  1,  0, 19,  4,  5,  4,  5,  5,  6,  6,  6,  0,  0,  6,\n",
       "        5,  3,  7,  4, 10, 14,  4,  6,  4, 17,  6, 19,  4, 12,  3,  2,  9,\n",
       "        5,  6,  6,  6, 18,  3,  0, 19,  6, 10,  1, 19,  6, 19,  4,  0,  4,\n",
       "        6,  5,  2,  7,  0,  6, 17,  6, 15,  6, 12,  3, 16,  6,  6, 14,  6,\n",
       "       13,  6,  4,  0,  6,  4, 18,  5,  7,  4, 19,  1, 16, 12,  1,  4,  6,\n",
       "        1, 18, 18, 14, 15, 12], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pip install torch\n",
    "np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d859ee03",
   "metadata": {},
   "source": [
    "Le modèle pré-entrainé se base sur une classe \"NewsGroupsDataset\", permettant de classifier les thèmes de différents articles de journaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52803942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class NewsGroupsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "train_dataset = NewsGroupsDataset(X_train_encoded, np.array(y_train))\n",
    "test_dataset = NewsGroupsDataset(X_test_encoded, np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ac58418",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "target = list(df['type_num'].unique())\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    model, num_labels=len(target))\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # chemin de stockage des résultats\n",
    "    num_train_epochs=3,              # nombre d'époques pour l'entraînement\n",
    "    per_device_train_batch_size=10,  # batch size pour l'entraînement\n",
    "    per_device_eval_batch_size=10,   # batch size pour l'évaluation du modèle\n",
    "    warmup_steps=500,                # nombre d'étapes pour le pas d'apprentissage\n",
    "    weight_decay=0.01,               # paramètre décidant des poids\n",
    "    logging_dir='./logs',            # chemin de stockage des logs\n",
    "    # utilisation du meilleur modèle à l'issu de l'entraînement\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=400,               # log & enregistrer les poids à chaque étape\n",
    "    save_steps=400,\n",
    "    evaluation_strategy=\"steps\",     # évaluation à chaque `logging_steps`\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84405968",
   "metadata": {},
   "source": [
    "On entraine le modèle, sur seulement 3 epochs car il est particulièrement fastidieux à exécuter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13b08ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexj\\Documents\\Anaconda\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 907\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 10\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 10\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 273\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='273' max='273' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [273/273 2:50:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 227\n",
      "  Batch size = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 04:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.355896234512329,\n",
       " 'eval_runtime': 289.1585,\n",
       " 'eval_samples_per_second': 0.785,\n",
       " 'eval_steps_per_second': 0.08,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caace11c",
   "metadata": {},
   "source": [
    "On définit une fonction qui nous permet de tester ce modèle : cette fonction prend en entrée un texte (par exemple l'OCR-isation d'un document) et en ressort une classe identifiée. Ici, on va utiliser des textes inventés, supposés être représentatifs de certaines classes de notre dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bcd9da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(text):\n",
    "    inputs = tokenizer(text, padding=True, truncation=True,\n",
    "                       max_length=max_length, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    probs = outputs[0].softmax(1)\n",
    "    return list(df['type_num'].unique())[probs.argmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d2ecd0",
   "metadata": {},
   "source": [
    "D'abord une carte postale :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5aba58be",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Hello mom and dad, we have arrived at Biarritz where the sun is shining and everything is cool. See you soon, kisses, bye'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2181d6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(pipeline(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e4cb02",
   "metadata": {},
   "source": [
    "Ici le type a bien été détecté, la correspondance index/type est décrite ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37e520eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type             type_num\n",
       "scientific_doc   6           351\n",
       "paye             4           145\n",
       "id_pieces        1            82\n",
       "carte postale    5            70\n",
       "facture          0            66\n",
       "passeport        3            43\n",
       "handwritten      17           35\n",
       "news_article     15           32\n",
       "questionnaire    19           31\n",
       "memo             12           31\n",
       "resume           10           30\n",
       "letter           9            29\n",
       "presentation     16           25\n",
       "budget           14           25\n",
       "specification    11           24\n",
       "invoice          13           24\n",
       "justif_domicile  2            23\n",
       "email            18           23\n",
       "advertisement    8            23\n",
       "form             7            22\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['type', 'type_num']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb48b8be",
   "metadata": {},
   "source": [
    "Puis une facture :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "00b484c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "text2 = 'Frank Bennett, Invoice, 29 cups, $56,  Total without tax : $152'\n",
    "print(pipeline(text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc15cb30",
   "metadata": {},
   "source": [
    "Puis un email :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a02ab5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "text3 = 'To : Maxwell Grant From : Jack Nicholson Subject : Payment missed last month Message : Hi Max, you have missed last month payment, please correct ASAP. Regards,'\n",
    "print(pipeline(text3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b9a511",
   "metadata": {},
   "source": [
    "On voit que dans ces deux derniers cas, le modèle semble avoir le même biais que dans notre analyse principale : s'il n'est pas sûr, il classe les documents dans la classe prépondérante, à savoir le document scientifique.\n",
    "Le modèle ne semble pas particulièrement robuste."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
